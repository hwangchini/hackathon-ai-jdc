from enum import Enum
from typing import Dict, Any, Optional, Literal
from langgraph.graph import StateGraph, END
from src.models.llm import get_llm
from src.agents.medicine_agent import MedicineAgent
from src.agents.graph_state import GraphState
from src.tools.medical_tools import MedicalTools


class IntentType(Enum):
    """C√°c lo·∫°i intent trong cu·ªôc h·ªôi tho·∫°i"""
    MEDICAL_CONSULTATION = "medical_consultation"
    DOCTOR_RECOMMENDATION = "doctor_recommendation"
    MEDICINE_INQUIRY = "medicine_inquiry"
    GENERAL_CHAT = "general_chat"


class AgentRouterGraph:
    """Agent Router s·ª≠ d·ª•ng LangGraph + Tools"""
    
    def __init__(self, vector_service=None):
        self.llm = get_llm(streaming=False)
        self.vector_service = vector_service
        self.medicine_agent = MedicineAgent(vector_service)
        
        # ‚úÖ Initialize tools
        if vector_service:
            self.medical_tools = MedicalTools(vector_service)
            self.tools = self.medical_tools.get_all_tools()
        else:
            self.tools = []
        
        # Build graph
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """X√¢y d·ª±ng LangGraph workflow"""
        workflow = StateGraph(GraphState)
        
        # Add nodes
        workflow.add_node("classify_intent", self.classify_intent_node)
        workflow.add_node("check_symptoms", self.check_symptoms_node)
        workflow.add_node("get_medical_context", self.get_medical_context_node)
        workflow.add_node("get_doctor_context", self.get_doctor_context_node)
        workflow.add_node("get_medicine_context", self.get_medicine_context_node)
        workflow.add_node("build_response", self.build_response_node)
        
        # Set entry point
        workflow.set_entry_point("classify_intent")
        
        # Add conditional edges
        workflow.add_conditional_edges(
            "classify_intent",
            self.route_by_intent,
            {
                "medical_consultation": "get_medical_context",
                "doctor_recommendation": "check_symptoms",
                "medicine_inquiry": "check_symptoms",
                "general_chat": "build_response"
            }
        )
        
        workflow.add_conditional_edges(
            "check_symptoms",
            self.route_by_symptoms,
            {
                "has_symptoms_doctor": "get_doctor_context",
                "has_symptoms_medicine": "get_medicine_context",
                "no_symptoms": "build_response"
            }
        )
        
        workflow.add_edge("get_medical_context", "build_response")
        workflow.add_edge("get_doctor_context", "build_response")
        workflow.add_edge("get_medicine_context", "build_response")
        workflow.add_edge("build_response", END)
        
        return workflow.compile()
    
    # ==================== NODES ====================
    
    def classify_intent_node(self, state: GraphState) -> GraphState:
        """Node: Ph√¢n lo·∫°i intent b·∫±ng LLM (kh√¥ng d√πng keyword)"""
        user_message = state["user_message"]
        
        # S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n lo·∫°i v·ªõi prompt chi ti·∫øt
        prompt = f"""Ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† x√°c ƒë·ªãnh intent (m·ª•c ƒë√≠ch).

C√¢u h·ªèi: "{user_message}"

**C√°c lo·∫°i intent:**

1. **MEDICAL_CONSULTATION** - T∆∞ v·∫•n y t·∫ø, ph√¢n t√≠ch tri·ªáu ch·ª©ng
   - Ng∆∞·ªùi d√πng M√î T·∫¢ tri·ªáu ch·ª©ng ƒëang g·∫∑p
   - H·ªèi v·ªÅ nguy√™n nh√¢n, ch·∫©n ƒëo√°n b·ªánh
   - VD: "t√¥i b·ªã ƒëau ƒë·∫ßu", "con t√¥i s·ªët cao", "tri·ªáu ch·ª©ng n√†y l√† g√¨?"

2. **DOCTOR_RECOMMENDATION** - G·ª£i √Ω b√°c sƒ©, chuy√™n khoa
   - H·ªèi v·ªÅ b√°c sƒ©, ph√≤ng kh√°m, chuy√™n khoa
   - Mu·ªën t√¨m b√°c sƒ© ƒë·ªÉ kh√°m
   - VD: "b√°c sƒ© n√†o gi·ªèi?", "t√¥i n√™n ƒëi kh√°m ·ªü ƒë√¢u?", "g·ª£i √Ω b√°c sƒ©"

3. **MEDICINE_INQUIRY** - H·ªèi v·ªÅ thu·ªëc, li·ªÅu d√πng
   - H·ªèi v·ªÅ thu·ªëc ƒëi·ªÅu tr·ªã
   - Li·ªÅu l∆∞·ª£ng, c√°ch d√πng thu·ªëc
   - VD: "t√¥i n√™n u·ªëng thu·ªëc g√¨?", "li·ªÅu d√πng paracetamol?", "thu·ªëc n√†y c√≥ t√°c d·ª•ng ph·ª• kh√¥ng?"

4. **GENERAL_CHAT** - Tr√≤ chuy·ªán th√¥ng th∆∞·ªùng
   - Ch√†o h·ªèi, c·∫£m ∆°n, xin l·ªói
   - H·ªèi v·ªÅ AI, h·ªá th·ªëng
   - VD: "xin ch√†o", "c·∫£m ∆°n", "b·∫°n l√† ai?"

**H√£y ph√¢n t√≠ch v√† CH·ªà tr·∫£ l·ªùi T√äN intent (m·ªôt trong 4 lo·∫°i tr√™n):**

Intent:"""
        
        try:
            response = self.llm.invoke(prompt)
            intent_text = response.content.strip().upper()
            
            # Parse response
            if "MEDICINE_INQUIRY" in intent_text or "MEDICINE" in intent_text:
                intent = IntentType.MEDICINE_INQUIRY.value
            elif "DOCTOR_RECOMMENDATION" in intent_text or "DOCTOR" in intent_text:
                intent = IntentType.DOCTOR_RECOMMENDATION.value
            elif "MEDICAL_CONSULTATION" in intent_text or "MEDICAL" in intent_text:
                intent = IntentType.MEDICAL_CONSULTATION.value
            else:
                intent = IntentType.GENERAL_CHAT.value
            
            print(f"üéØ Intent: {intent} (LLM classified)")
        except Exception as e:
            print(f"‚ö†Ô∏è LLM classification error: {str(e)}")
            intent = IntentType.GENERAL_CHAT.value
        
        state["intent"] = intent
        return state
    
    def check_symptoms_node(self, state: GraphState) -> GraphState:
        """Node: Ki·ªÉm tra tri·ªáu ch·ª©ng b·∫±ng LLM"""
        check_context = state.get("user_only_context", "") or state.get("conversation_context", "")
        
        if not check_context or len(check_context.strip()) < 5:
            state["has_symptoms"] = False
            return state
        
        prompt = f"""Ph√¢n t√≠ch: Ng∆∞·ªùi d√πng ƒë√£ M√î T·∫¢ tri·ªáu ch·ª©ng b·ªánh l√Ω hay ch∆∞a?

L·ªãch s·ª≠ tin nh·∫Øn: "{check_context}"

QUY T·∫ÆC PH√ÇN BI·ªÜT:

‚úÖ C√ì tri·ªáu ch·ª©ng (ng∆∞·ªùi d√πng M√î T·∫¢ t√¨nh tr·∫°ng s·ª©c kh·ªèe):
- "t√¥i b·ªã ƒëau ƒë·∫ßu"
- "con t√¥i s·ªët 39 ƒë·ªô"
- "t√¥i ƒëang ho, kh√≥ th·ªü"
- "b·ª•ng t√¥i ƒëau qu·∫∑n"
- "t√¥i c·∫£m th·∫•y ch√≥ng m·∫∑t"

‚ùå KH√îNG c√≥ tri·ªáu ch·ª©ng (ch·ªâ H·ªéI, CH∆ØA M√î T·∫¢):
- "t√¥i n√™n u·ªëng thu·ªëc g√¨?"
- "g·ª£i √Ω b√°c sƒ© cho t√¥i"
- "ƒëau ƒë·∫ßu l√† b·ªánh g√¨?"
- "b√°c sƒ© n√†o gi·ªèi?"
- "thu·ªëc g√¨ t·ªët?"

QUAN TR·ªåNG: 
- Ng∆∞·ªùi d√πng ph·∫£i M√î T·∫¢ r√µ r√†ng h·ªç ƒêANG g·∫∑p tri·ªáu ch·ª©ng g√¨
- Ch·ªâ H·ªéI v·ªÅ thu·ªëc/b√°c sƒ© M√Ä KH√îNG n√≥i tri·ªáu ch·ª©ng = CH∆ØA c√≥

CH·ªà tr·∫£ l·ªùi: "C√ì" ho·∫∑c "KH√îNG"

Tr·∫£ l·ªùi:"""
        
        try:
            response = self.llm.invoke(prompt)
            answer = response.content.strip().upper()
            has_symptoms = "C√ì" in answer or "CO" in answer
            
            print(f"ü§ñ LLMÂà§Êñ≠: '{answer}' ‚Üí Has symptoms: {has_symptoms}")
            state["has_symptoms"] = has_symptoms
        except Exception as e:
            print(f"‚ö†Ô∏è LLM error: {str(e)}")
            state["has_symptoms"] = False
        
        return state
    
    def get_medical_context_node(self, state: GraphState) -> GraphState:
        """Node: L·∫•y context y t·∫ø"""
        if not self.vector_service or not self.vector_service.vector_store:
            state["medical_context"] = None
            return state
        
        try:
            docs = self.vector_service.similarity_search(state["user_message"], k=3)
            
            if docs:
                context_parts = []
                for i, doc in enumerate(docs, 1):
                    name = doc.metadata.get('symptom_name', doc.metadata.get('item_name', f'Doc {i}'))
                    context_parts.append(f"{'='*60}\n{name.upper()}\n{'='*60}\n{doc.page_content}")
                
                context = "\n\n".join(context_parts)
                state["medical_context"] = f"TH√îNG TIN Y T·∫æ:\n\n{context}\n\n{'='*60}\n"
            else:
                state["medical_context"] = None
        except Exception as e:
            print(f"‚ö†Ô∏è Error: {str(e)}")
            state["medical_context"] = None
        
        return state
    
    def normalize_text(self, text: str) -> str:
        """Chu·∫©n h√≥a text ƒë·ªÉ search t·ªët h∆°n"""
        import unicodedata
        text = unicodedata.normalize('NFKD', text)
        text = ''.join([c for c in text if not unicodedata.combining(c)])
        return text.lower().strip()
    
    def get_doctor_recommendations_logic(self, user_message: str, conversation_context: str = "") -> Optional[str]:
        """Logic t√¨m b√°c sƒ© (di chuy·ªÉn t·ª´ router.py)"""
        if not self.vector_service or not self.vector_service.vector_store:
            return None
        
        try:
            # Tr√≠ch xu·∫•t tri·ªáu ch·ª©ng
            symptoms_text = ""
            if conversation_context:
                extract_prompt = f"""T·ª´ l·ªãch s·ª≠, li·ªát k√™ tri·ªáu ch·ª©ng:
{conversation_context}

Tri·ªáu ch·ª©ng:"""
                response = self.llm.invoke(extract_prompt)
                symptoms_text = response.content.strip()
            
            # Map tri·ªáu ch·ª©ng ‚Üí chuy√™n khoa
            symptom_to_specialty = {
                'ƒëau ƒë·∫ßu': ['N·ªôi khoa', 'Tim m·∫°ch', 'N·ªôi ti·∫øt'],
                'ƒëau b·ª•ng': ['Ti√™u h√≥a', 'N·ªôi khoa'],
                '·ª£ n√≥ng': ['Ti√™u h√≥a'],
                'ti√™u ch·∫£y': ['Ti√™u h√≥a'],
                't√°o b√≥n': ['Ti√™u h√≥a'],
                'ƒëau ng·ª±c': ['Tim m·∫°ch', 'N·ªôi khoa'],
                'kh√≥ th·ªü': ['Tim m·∫°ch', 'H·ªìi s·ª©c t√≠ch c·ª±c'],
                'ho': ['Tai-M≈©i-H·ªçng'],
                's·ªï m≈©i': ['Tai-M≈©i-H·ªçng'],
                'ƒëau h·ªçng': ['Tai-M≈©i-H·ªçng'],
                'm·ªù m·∫Øt': ['M·∫Øt'],
                'ng·ª©a': ['Da li·ªÖu'],
                'ph√°t ban': ['Da li·ªÖu'],
            }
            
            possible_specialties = []
            symptoms_lower = symptoms_text.lower()
            for symptom, specialties in symptom_to_specialty.items():
                if symptom in symptoms_lower:
                    possible_specialties.extend(specialties)
            
            possible_specialties = list(set(possible_specialties))
            
            if not possible_specialties:
                specialty_prompt = f"""Tri·ªáu ch·ª©ng: {symptoms_text}
Ch·ªçn khoa: Tim m·∫°ch, Ti√™u h√≥a, N·ªôi ti·∫øt, Tai-M≈©i-H·ªçng, M·∫Øt, Da li·ªÖu
Ch·ªâ tr·∫£ v·ªÅ T√äN KHOA:"""
                response = self.llm.invoke(specialty_prompt)
                possible_specialties = [response.content.strip()]
            
            # Search v·ªõi cosine similarity
            all_results_with_scores = []
            for specialty in possible_specialties:
                queries = [
                    specialty,
                    f"khoa {specialty}",
                    f"b√°c sƒ© {specialty}",
                    self.normalize_text(specialty)
                ]
                
                for query in queries:
                    results = self.vector_service.similarity_search_with_scores(query, k=3)
                    all_results_with_scores.extend(results)
            
            # L·ªçc v√† rank
            dept_scores = {}
            for doc, cosine_score in all_results_with_scores:
                if doc.metadata.get('filename') == 'medical_personnel.json':
                    dept_name = doc.metadata.get('department_name')
                    if dept_name:
                        total_score = cosine_score
                        
                        # Bonus t·ª´ text matching
                        dept_lower = dept_name.lower()
                        specialty_lower = doc.metadata.get('specialty_name', '').lower()
                        
                        for spec in possible_specialties:
                            if spec.lower() in dept_lower:
                                total_score += 0.2
                            if spec.lower() in specialty_lower:
                                total_score += 0.1
                        
                        if dept_name not in dept_scores or dept_scores[dept_name]['score'] < total_score:
                            dept_scores[dept_name] = {
                                'doc': doc,
                                'score': total_score,
                                'cosine_score': cosine_score
                            }
            
            # Sort v√† format
            sorted_depts = sorted(dept_scores.items(), key=lambda x: x[1]['score'], reverse=True)
            doctor_docs = [item[1]['doc'] for item in sorted_depts[:3]]
            
            if doctor_docs:
                context_parts = []
                for doc in doctor_docs:
                    specialty_name = doc.metadata.get('specialty_name', 'N/A')
                    dept_name = doc.metadata.get('department_name', 'N/A')
                    context_parts.append(f"{'='*60}\n{dept_name.upper()} - {specialty_name}\n{'='*60}\n{doc.page_content}")
                
                context = "\n\n".join(context_parts)
                return f"TH√îNG TIN B√ÅC Sƒ®:\n\n{context}\n\n{'='*60}\n"
            
            return None
            
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói: {str(e)}")
            return None
    
    def get_doctor_context_node(self, state: GraphState) -> GraphState:
        """Node: L·∫•y context b√°c sƒ© - Hybrid approach"""
        
        # ‚úÖ OPTION 1: Try using tool first (fast & accurate)
        if self.tools and state.get("user_message"):
            try:
                # Extract specialty from conversation
                extract_prompt = f"""T·ª´ c√¢u h·ªèi, x√°c ƒë·ªãnh chuy√™n khoa:
{state['user_message']}

L·ªãch s·ª≠: {state['conversation_context']}

Ch·ªâ tr·∫£ v·ªÅ T√äN CHUY√äN KHOA (Tim m·∫°ch, Ti√™u h√≥a, Tai-M≈©i-H·ªçng, Da li·ªÖu, M·∫Øt, N·ªôi ti·∫øt)
N·∫øu kh√¥ng r√µ, tr·∫£ v·ªÅ "N·ªôi khoa"

Chuy√™n khoa:"""
                
                response = self.llm.invoke(extract_prompt)
                specialty = response.content.strip()
                
                print(f"üîß Using tool: search_doctors_by_specialty('{specialty}')")
                
                # Use tool
                tool_result = self.medical_tools.search_doctors_by_specialty(specialty)
                
                if tool_result and "Kh√¥ng t√¨m th·∫•y" not in tool_result:
                    doctor_context = f"TH√îNG TIN B√ÅC Sƒ®:\n\n{tool_result}\n\n{'='*60}\n"
                    state["doctor_context"] = doctor_context
                    print(f"‚úÖ Tool returned doctor context")
                    return state
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Tool failed: {str(e)}, fallback to original method")
        
        # ‚úÖ OPTION 2: Fallback to original vector search
        print(f"üîÑ Fallback to original vector search")
        doctor_context = self.get_doctor_recommendations_logic(
            state["user_message"],
            state["conversation_context"]
        )
        
        state["doctor_context"] = doctor_context
        return state
    
    def get_medicine_context_node(self, state: GraphState) -> GraphState:
        """Node: L·∫•y context thu·ªëc"""
        medicine_context = self.medicine_agent.search_medicine_by_symptoms(
            state["user_message"],
            state["conversation_context"]
        )
        
        # ‚úÖ DEBUG
        if medicine_context:
            print(f"‚úÖ Medicine context received: {len(medicine_context)} chars")
        else:
            print(f"‚ùå Medicine context is None or empty")
        
        state["medicine_context"] = medicine_context
        return state
    
    def build_response_node(self, state: GraphState) -> GraphState:
        """Node: X√¢y d·ª±ng response cu·ªëi c√πng"""
        intent = state["intent"]
        
        if intent == "medical_consultation":
            if state.get("medical_context"):
                state["use_context"] = True
                state["system_prompt"] = """B·∫°n l√† tr·ª£ l√Ω y t·∫ø AI chuy√™n nghi·ªáp. 
Nhi·ªám v·ª•:
1. GHI NH·ªö t·∫•t c·∫£ tri·ªáu ch·ª©ng
2. Ph√¢n t√≠ch tri·ªáu ch·ª©ng
3. Ch·∫©n ƒëo√°n kh·∫£ nƒÉng b·ªánh l√Ω
4. ƒê∆∞a ra l·ªùi khuy√™n

L∆ØU √ù: ƒê√¢y ch·ªâ l√† th√¥ng tin tham kh·∫£o."""
                state["prompt"] = f"""{state['medical_context']}

C√¢u h·ªèi: {state['user_message']}

Ph√¢n t√≠ch v√† t∆∞ v·∫•n:"""
            else:
                state["use_context"] = False
                state["system_prompt"] = "B·∫°n l√† tr·ª£ l√Ω y t·∫ø AI."
                state["prompt"] = f"{state['user_message']}\n\nKHUY·∫æN NGH·ªä g·∫∑p b√°c sƒ©."
        
        elif intent == "doctor_recommendation":
            if not state.get("has_symptoms"):
                state["use_context"] = False
                state["system_prompt"] = "B·∫°n l√† tr·ª£ l√Ω y t·∫ø AI. KH√îNG t·ª± b·ªãa tri·ªáu ch·ª©ng."
                state["prompt"] = f"""Ng∆∞·ªùi d√πng h·ªèi: {state['user_message']}

QUAN TR·ªåNG: Ng∆∞·ªùi d√πng CH∆ØA cung c·∫•p tri·ªáu ch·ª©ng c·ª• th·ªÉ.

H√£y tr·∫£ l·ªùi:
"ƒê·ªÉ g·ª£i √Ω b√°c sƒ© ph√π h·ª£p, t√¥i c·∫ßn bi·∫øt th√™m th√¥ng tin v·ªÅ t√¨nh tr·∫°ng s·ª©c kh·ªèe c·ªßa b·∫°n.

Vui l√≤ng cho t√¥i bi·∫øt:
- B·∫°n ƒëang g·∫∑p tri·ªáu ch·ª©ng g√¨?
- Tri·ªáu ch·ª©ng xu·∫•t hi·ªán t·ª´ bao l√¢u?
- M·ª©c ƒë·ªô nghi√™m tr·ªçng nh∆∞ th·∫ø n√†o?"

KH√îNG t·ª± b·ªãa tri·ªáu ch·ª©ng."""
            elif state.get("doctor_context"):
                state["use_context"] = True
                state["system_prompt"] = """B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n b√°c sƒ©.
QUY T·∫ÆC:
- CH·ªà d√πng tri·ªáu ch·ª©ng t·ª´ l·ªãch s·ª≠
- KH√îNG t·ª± b·ªãa
- PH·∫¢I ƒë√∫ng chuy√™n khoa"""
                state["prompt"] = f"""L·ªãch s·ª≠: {state['conversation_context']}

{state['doctor_context']}

C√¢u h·ªèi: {state['user_message']}

Format:
**Tri·ªáu ch·ª©ng**: [T·ª´ l·ªãch s·ª≠]
**Chuy√™n khoa**: [T√™n]
**B√°c sƒ©**:
1. [H·ªç t√™n] - [H·ªçc v·ªã] - [Ch·ª©c v·ª•] - [Khoa]"""
            else:
                state["use_context"] = False
                state["system_prompt"] = "B·∫°n l√† tr·ª£ l√Ω y t·∫ø."
                state["prompt"] = f"""Kh√¥ng t√¨m th·∫•y b√°c sƒ©.

H√£y khuy√™n:
1. M√¥ t·∫£ r√µ tri·ªáu ch·ª©ng
2. G·ªçi 115 ho·∫∑c 19003115"""
        
        elif intent == "medicine_inquiry":
            if not state.get("has_symptoms"):
                state["use_context"] = False
                state["system_prompt"] = "B·∫°n l√† d∆∞·ª£c sƒ© AI. KH√îNG t·ª± b·ªãa tri·ªáu ch·ª©ng."
                state["prompt"] = f"""Ng∆∞·ªùi d√πng h·ªèi: {state['user_message']}

QUAN TR·ªåNG: Ng∆∞·ªùi d√πng CH∆ØA cung c·∫•p tri·ªáu ch·ª©ng c·ª• th·ªÉ.

H√£y tr·∫£ l·ªùi:
"ƒê·ªÉ g·ª£i √Ω thu·ªëc v√† li·ªÅu l∆∞·ª£ng s·ª≠ d·ª•ng, ch·∫ø ƒë·ªô ngh·ªâ ng∆°i ph√π h·ª£p, t√¥i c·∫ßn bi·∫øt th√™m th√¥ng tin v·ªÅ t√¨nh tr·∫°ng s·ª©c kh·ªèe c·ªßa b·∫°n.

Vui l√≤ng cho t√¥i bi·∫øt:
- B·∫°n ƒëang g·∫∑p tri·ªáu ch·ª©ng g√¨?
- Tri·ªáu ch·ª©ng xu·∫•t hi·ªán t·ª´ bao l√¢u?
- M·ª©c ƒë·ªô nghi√™m tr·ªçng nh∆∞ th·∫ø n√†o?"

KH√îNG t·ª± b·ªãa tri·ªáu ch·ª©ng ho·∫∑c t∆∞ v·∫•n thu·ªëc."""
            elif state.get("medicine_context"):
                # ‚úÖ DEBUG
                print(f"‚úÖ Using medicine context in response")
                
                state["use_context"] = True
                state["system_prompt"] = """B·∫°n l√† d∆∞·ª£c sƒ© AI.
QUY T·∫ÆC:
- CH·ªà t∆∞ v·∫•n OTC
- C·∫£nh b√°o t√°c d·ª•ng ph·ª•
- Khuy√™n tham kh·∫£o b√°c sƒ©"""
                state["prompt"] = f"""{state['medicine_context']}

C√¢u h·ªèi: {state['user_message']}

T∆∞ v·∫•n thu·ªëc v√† khuy·∫øn ngh·ªã:"""
            else:
                # ‚úÖ DEBUG
                print(f"‚ùå No medicine context, using fallback response")
                
                state["use_context"] = False
                state["system_prompt"] = "B·∫°n l√† d∆∞·ª£c sƒ© AI th√¢n thi·ªán v√† l·ªãch s·ª±."
                state["prompt"] = f"""Ng∆∞·ªùi d√πng h·ªèi: {state['user_message']}

QUAN TR·ªåNG: Kh√¥ng t√¨m th·∫•y th√¥ng tin thu·ªëc ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu.

H√£y tr·∫£ l·ªùi m·ªôt c√°ch l·ªãch s·ª± v√† h·ªØu √≠ch:
"Xin l·ªói, hi·ªán t·∫°i t√¥i ch∆∞a c√≥ th√¥ng tin chi ti·∫øt v·ªÅ thu·ªëc ph√π h·ª£p cho tri·ªáu ch·ª©ng c·ªßa b·∫°n trong c∆° s·ªü d·ªØ li·ªáu c·ªßa m√¨nh.

ƒê·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n ch√≠nh x√°c v·ªÅ thu·ªëc v√† li·ªÅu l∆∞·ª£ng ph√π h·ª£p, t√¥i khuy√™n b·∫°n:

1. **ƒê·∫øn ph√≤ng kh√°m ho·∫∑c b·ªánh vi·ªán g·∫ßn nh·∫•t** ƒë·ªÉ ƒë∆∞·ª£c b√°c sƒ© kh√°m v√† k√™ ƒë∆°n thu·ªëc ph√π h·ª£p
2. **Tham kh·∫£o d∆∞·ª£c sƒ© t·∫°i nh√† thu·ªëc** ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n tr·ª±c ti·∫øp v·ªÅ thu·ªëc kh√¥ng k√™ ƒë∆°n
3. **G·ªçi t·ªïng ƒë√†i t∆∞ v·∫•n y t·∫ø**: 
   - T·ªïng ƒë√†i 115 (c·∫•p c·ª©u)
   - Hotline t∆∞ v·∫•n d∆∞·ª£c: 19003190

**L∆∞u √Ω quan tr·ªçng:** Kh√¥ng t·ª± √Ω mua v√† s·ª≠ d·ª•ng thu·ªëc m√† ch∆∞a c√≥ ch·ªâ ƒë·ªãnh c·ªßa b√°c sƒ© ho·∫∑c d∆∞·ª£c sƒ©, v√¨ c√≥ th·ªÉ g√¢y ra t√°c d·ª•ng ph·ª• kh√¥ng mong mu·ªën."

H√£y th·ªÉ hi·ªán s·ª± quan t√¢m v√† h·ªó tr·ª£ t·ªëi ƒëa c√≥ th·ªÉ."""
        
        else:  # general_chat
            state["use_context"] = False
            state["system_prompt"] = "B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán."
            state["prompt"] = state["user_message"]
        
        return state
    
    # ==================== CONDITIONAL EDGES ====================
    
    def route_by_intent(self, state: GraphState) -> str:
        """Route d·ª±a tr√™n intent"""
        return state["intent"]
    
    def route_by_symptoms(self, state: GraphState) -> str:
        """Route d·ª±a tr√™n c√≥ tri·ªáu ch·ª©ng hay kh√¥ng"""
        if not state.get("has_symptoms"):
            return "no_symptoms"
        
        if state["intent"] == "doctor_recommendation":
            return "has_symptoms_doctor"
        else:  # medicine_inquiry
            return "has_symptoms_medicine"
    
    # ==================== PUBLIC API ====================
    
    def route(self, user_message: str, conversation_context: str = "", user_only_context: str = "") -> Dict[str, Any]:
        """
        Main entry point - gi·ªëng API c≈©
        
        Returns:
            Dict v·ªõi keys: intent, use_context, system_prompt, prompt
        """
        print(f"\n{'='*60}")
        print(f"üîç LANGGRAPH ROUTER")
        print(f"{'='*60}")
        print(f"User: {user_message}")
        print(f"User context: '{user_only_context[:50]}...'")
        print(f"{'='*60}\n")
        
        # Prepare initial state
        initial_state: GraphState = {
            "user_message": user_message,
            "conversation_context": conversation_context,
            "user_only_context": user_only_context,
            "intent": "general_chat",
            "has_symptoms": None,
            "medical_context": None,
            "doctor_context": None,
            "medicine_context": None,
            "system_prompt": "",
            "prompt": "",
            "use_context": False
        }
        
        # Run graph
        final_state = self.graph.invoke(initial_state)
        
        # Return response
        return {
            "intent": final_state["intent"],
            "use_context": final_state["use_context"],
            "system_prompt": final_state["system_prompt"],
            "prompt": final_state["prompt"]
        }
